{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfee1ab",
   "metadata": {},
   "source": [
    "# Análisis de Comunidades en Redes: Guía de Estudio\n",
    "\n",
    "Esta guía proporciona una estructura para el estudio del análisis de comunidades en redes.\n",
    "\n",
    "## Estructura del Estudio\n",
    "\n",
    "1. Descripción y Preparación del Dataset\n",
    "2. Análisis de Estructura de Red\n",
    "3. Métodos de Detección de Comunidades\n",
    "4. Visualización de Comunidades\n",
    "5. Métricas y Evaluación de Comunidades\n",
    "6. Análisis Temporal de Comunidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a30a57",
   "metadata": {},
   "source": [
    "# 1. Descripción y Preparación del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc0aa1",
   "metadata": {},
   "source": [
    "## 1.1 Tipos de Redes para Análisis\n",
    "* Redes sociales\n",
    "* Redes biológicas\n",
    "* Redes de información\n",
    "* Redes tecnológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaefcb9d",
   "metadata": {},
   "source": [
    "## 1.2 Requisitos de los Datos\n",
    "* Formato de datos de entrada\n",
    "* Estructuras de grafos\n",
    "* Matrices de adyacencia\n",
    "* Listas de enlaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f3467",
   "metadata": {},
   "source": [
    "## 1.3 Preparación de Datos\n",
    "* Limpieza de datos\n",
    "* Normalización\n",
    "* Manejo de datos faltantes\n",
    "* Filtrado de conexiones\n",
    "\n",
    "**Nota**: En esta sección implementaremos:\n",
    "* Carga de datos\n",
    "* Conversión de formatos\n",
    "* Limpieza básica\n",
    "* Creación de estructura de grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f58abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga y creación de muestra para edgelist grande\n",
    "import os\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "DATAFILE = 'wiki-topcats.txt'  # ajustar ruta si procede\n",
    "SAMPLE_PATH = 'wiki-topcats-sample.txt'\n",
    "\n",
    "def file_size_mb(path):\n",
    "    try:\n",
    "        return os.path.getsize(path) / (1024*1024)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def build_sample(path, max_lines=200000, save_sample=False):\n",
    "    G = nx.Graph()\n",
    "    if not os.path.exists(path):\n",
    "        print('Archivo no encontrado:', path)\n",
    "        return G\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if max_lines and i >= max_lines:\n",
    "                break\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            u, v = parts[0], parts[1]\n",
    "            G.add_edge(u, v)\n",
    "    if save_sample:\n",
    "        with open(SAMPLE_PATH, 'w', encoding='utf-8') as out:\n",
    "            for u, v in G.edges():\n",
    "                out.write(f\"{u} {v}\\n\")\n",
    "        print('Muestra guardada en', SAMPLE_PATH)\n",
    "    return G\n",
    "\n",
    "# Selección automática: si el archivo es muy grande, usar muestra\n",
    "size = file_size_mb(DATAFILE)\n",
    "if size is None:\n",
    "    print('No se encontró', DATAFILE, 'en el directorio actual. Ajusta DATAFILE si es necesario.')\n",
    "    G = nx.Graph()\n",
    "else:\n",
    "    print(f'File size: {size:.1f} MB')\n",
    "    if size > 150:\n",
    "        print('Archivo grande detectado. Construyendo muestra de 200k líneas...')\n",
    "        G = build_sample(DATAFILE, max_lines=200000, save_sample=False)\n",
    "    else:\n",
    "        print('Archivo moderado/pequeño. Construyendo grafo completo...')\n",
    "        G = build_sample(DATAFILE, max_lines=None, save_sample=False)\n",
    "\n",
    "print('Grafo construido: Nodos=', G.number_of_nodes(), 'Aristas=', G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8292e7",
   "metadata": {},
   "source": [
    "# 2. Análisis de Estructura de Red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251ad70",
   "metadata": {},
   "source": [
    "## 2.1 Métricas Básicas\n",
    "* Densidad de la red\n",
    "* Distribución de grado\n",
    "* Coeficiente de clustering\n",
    "* Longitud de camino promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c249f",
   "metadata": {},
   "source": [
    "## 2.2 Medidas de Centralidad\n",
    "* Centralidad de grado\n",
    "* Centralidad de intermediación\n",
    "* Centralidad de cercanía\n",
    "* Centralidad de eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842420ff",
   "metadata": {},
   "source": [
    "## 2.3 Propiedades Estructurales\n",
    "* Componentes conectados\n",
    "* Puentes y puntos de articulación\n",
    "* Triángulos y coeficientes locales\n",
    "* Patrones de conectividad\n",
    "\n",
    "**Nota**: En esta sección implementaremos:\n",
    "* Cálculo de métricas básicas\n",
    "* Análisis de centralidad\n",
    "* Visualización de distribuciones\n",
    "* Identificación de estructuras clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas básicas y centralidad (muestra)\n",
    "import statistics\n",
    "from collections import Counter\n",
    "\n",
    "if 'G' not in globals() or G is None or G.number_of_nodes() == 0:\n",
    "    print('Ejecuta la celda de carga de datos primero.')\n",
    "else:\n",
    "    n = G.number_of_nodes(); m = G.number_of_edges()\n",
    "    print(f'Nodos={n} Aristas={m}')\n",
    "\n",
    "    # Grado\n",
    "    degrees = [d for _, d in G.degree()]\n",
    "    print('Grado: min', min(degrees), 'max', max(degrees), 'mean', round(statistics.mean(degrees), 2))\n",
    "\n",
    "    # Densidad\n",
    "    print('Densidad:', nx.density(G))\n",
    "\n",
    "    # Clustering\n",
    "    try:\n",
    "        clustering_vals = nx.clustering(G)\n",
    "        print('Clustering medio:', round(statistics.mean(clustering_vals.values()), 4))\n",
    "    except Exception:\n",
    "        print('Error calculando clustering (grafo dirigido o muy grande)')\n",
    "\n",
    "    # Componentes\n",
    "    comps = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "    print('Número de componentes:', len(comps))\n",
    "    print('Tamaño de la componente gigante:', len(comps[0]) if comps else 0)\n",
    "\n",
    "    # Triángulos (local)\n",
    "    try:\n",
    "        tri = nx.triangles(G)\n",
    "        print('Número total de triángulos (sum/3):', sum(tri.values()) // 3)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Centralidades (rápido: grado; aproximado: betweenness con k)\n",
    "    deg_cent = nx.degree_centrality(G)\n",
    "    top_deg = sorted(deg_cent.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print('\\nTop 10 nodos por centralidad de grado:')\n",
    "    for node, val in top_deg:\n",
    "        print(node, round(val, 4))\n",
    "\n",
    "    try:\n",
    "        # k se ajusta para aproximar si el grafo es grande\n",
    "        k = 200 if n > 5000 else None\n",
    "        bet = nx.betweenness_centrality(G, k=k)\n",
    "        top_bet = sorted(bet.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        print('\\nTop 10 nodos por betweenness (aprox):')\n",
    "        for node, val in top_bet:\n",
    "            print(node, round(val, 4))\n",
    "    except Exception as e:\n",
    "        print('Betweenness skipped or failed:', e)\n",
    "\n",
    "    # Histograma de grado si matplotlib disponible\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.hist(degrees, bins=50, color='#3c8dbc')\n",
    "        plt.xlabel('Grado')\n",
    "        plt.ylabel('Frecuencia')\n",
    "        plt.title('Distribución de grado (muestra)')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print('No se pudo graficar distribución de grado:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4620d97",
   "metadata": {},
   "source": [
    "# 3. Métodos de Detección de Comunidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214a660",
   "metadata": {},
   "source": [
    "## 3.1 Algoritmos Fundamentales\n",
    "* Método de Louvain\n",
    "* Algoritmo de Girvan-Newman\n",
    "* Propagación de Etiquetas\n",
    "* Optimización de Modularidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16360b31",
   "metadata": {},
   "source": [
    "## 3.2 Características de Algoritmos\n",
    "* Complejidad computacional\n",
    "* Escalabilidad\n",
    "* Resolución límite\n",
    "* Ventajas y limitaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0db01a",
   "metadata": {},
   "source": [
    "## 3.3 Selección de Método\n",
    "* Criterios de selección\n",
    "* Tamaño de la red\n",
    "* Tipo de comunidades esperadas\n",
    "* Recursos computacionales\n",
    "\n",
    "**Nota**: En esta sección implementaremos:\n",
    "* Algoritmos de detección\n",
    "* Comparación de resultados\n",
    "* Análisis de rendimiento\n",
    "* Visualización de comunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d128f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de comunidades: Louvain, Label Propagation y demo Girvan-Newman\n",
    "from collections import Counter\n",
    "\n",
    "if 'G' not in globals() or G is None or G.number_of_nodes() == 0:\n",
    "    print('Ejecuta la celda de carga de datos primero.')\n",
    "else:\n",
    "    partition = None\n",
    "    # Louvain (recomendado)\n",
    "    try:\n",
    "        import community as community_louvain\n",
    "        partition = community_louvain.best_partition(G)\n",
    "        counts = Counter(partition.values())\n",
    "        print('Comunidades detectadas (Louvain):', len(counts))\n",
    "        print('Top 5 comunidades (Louvain):', counts.most_common(5))\n",
    "    except Exception as e:\n",
    "        print('python-louvain no disponible o falló:', e)\n",
    "        partition = None\n",
    "\n",
    "    # Label Propagation (rápido, sin dependencias externas)\n",
    "    try:\n",
    "        from networkx.algorithms.community import label_propagation\n",
    "        lp_comms = list(label_propagation.label_propagation_communities(G))\n",
    "        print('Comunidades (Label Propagation) detectadas:', len(lp_comms))\n",
    "    except Exception as e:\n",
    "        print('Label Propagation falló:', e)\n",
    "\n",
    "    # Girvan-Newman demo en subgrafo pequeño (solo ilustrativo)\n",
    "    try:\n",
    "        from networkx.algorithms import community as nx_comm\n",
    "        nodes_small = list(sorted(G.nodes(), key=lambda n: G.degree(n), reverse=True))[:300]\n",
    "        G_small = G.subgraph(nodes_small).copy()\n",
    "        comp_gen = nx_comm.girvan_newman(G_small)\n",
    "        top = tuple(sorted(c) for c in next(comp_gen))\n",
    "        print('Demo Girvan-Newman (subgrafo 300 nodos): comunidades en primer corte =', len(top))\n",
    "    except Exception as e:\n",
    "        print('Girvan-Newman demo falló:', e)\n",
    "\n",
    "    # leave partition in globals for later cells\n",
    "    if partition:\n",
    "        print('Partition dictionary available as `partition` (node -> community)')\n",
    "    else:\n",
    "        print('No partition available from Louvain; consider installing python-louvain if deseas esa partición.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b6b30",
   "metadata": {},
   "source": [
    "# 4. Visualización de Comunidades\n",
    "\n",
    "Técnicas efectivas para visualizar y comprender las estructuras comunitarias:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27bc82b",
   "metadata": {},
   "source": [
    "## 4.1 Técnicas de Visualización\n",
    "* Layouts de fuerza dirigida\n",
    "* Visualización jerárquica\n",
    "* Mapas de calor\n",
    "* Representaciones circulares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc2b63",
   "metadata": {},
   "source": [
    "## 4.2 Estrategias de Diseño\n",
    "* Codificación por colores\n",
    "* Agrupamiento visual\n",
    "* Escalado de nodos\n",
    "* Filtrado interactivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de81e3",
   "metadata": {},
   "source": [
    "## 4.3 Interpretación Visual\n",
    "* Patrones estructurales\n",
    "* Roles de nodos\n",
    "* Conexiones entre comunidades\n",
    "* Anomalías y casos especiales\n",
    "\n",
    "**Nota**: En esta sección implementaremos:\n",
    "* Creación de visualizaciones\n",
    "* Personalización de layouts\n",
    "* Interactividad\n",
    "* Exportación de gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf20d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\AppData\\Local\\Temp\\ipykernel_29360\\3677995847.py:22: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('tab20', max(1, len(unique_comms)))\n"
     ]
    }
   ],
   "source": [
    "# Visualización por comunidad (usa `partition` si está disponible)\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "if 'G' not in globals() or G is None or G.number_of_nodes() == 0:\n",
    "    print('Ejecuta la celda de carga de datos primero.')\n",
    "else:\n",
    "    # Determinar mapa de comunidades\n",
    "    if 'partition' in globals() and partition:\n",
    "        comm_map = partition\n",
    "    else:\n",
    "        # fallback: cada componente es su propia 'comunidad'\n",
    "        comm_map = {n: i for i, comp in enumerate(nx.connected_components(G)) for n in comp}\n",
    "\n",
    "    # Seleccionar la componente gigante para visualizar\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    Gv = G.subgraph(largest_cc).copy()\n",
    "\n",
    "    # Recalcular comm_map limitado a Gv\n",
    "    nodes = list(Gv.nodes())\n",
    "    unique_comms = sorted({comm_map.get(n, 0) for n in nodes})\n",
    "    cmap = plt.cm.get_cmap('tab20', max(1, len(unique_comms)))\n",
    "    color_list = [cmap(unique_comms.index(comm_map.get(n, 0))) for n in nodes]\n",
    "\n",
    "    pos = nx.spring_layout(Gv, seed=42, k=0.1, iterations=50)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    nx.draw_networkx_nodes(Gv, pos, node_size=20, node_color=color_list)\n",
    "    nx.draw_networkx_edges(Gv, pos, alpha=0.2, width=0.4)\n",
    "    plt.title('Componente gigante coloreada por comunidad')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Mostrar tamaños de comunidades en la componente gigante\n",
    "    size_by_comm = Counter(comm_map.get(n, 0) for n in nodes)\n",
    "    print('Comunidades en la componente gigante (top 10):', size_by_comm.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e10f41",
   "metadata": {},
   "source": [
    "# 5. Métricas y Evaluación de Comunidades\n",
    "\n",
    "Métodos para evaluar la calidad de las comunidades detectadas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d51f63",
   "metadata": {},
   "source": [
    "## 5.1 Métricas de Calidad\n",
    "* Modularidad\n",
    "* Conductancia\n",
    "* Cobertura\n",
    "* Rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c10e88",
   "metadata": {},
   "source": [
    "## 5.2 Evaluación Interna\n",
    "* Densidad intra-comunidad\n",
    "* Dispersión inter-comunidad\n",
    "* Cohesión\n",
    "* Separación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c3352e",
   "metadata": {},
   "source": [
    "## 5.3 Evaluación Externa\n",
    "* Ground truth comparación\n",
    "* Índice de Rand ajustado\n",
    "* Información mutua normalizada\n",
    "* F-measure\n",
    "\n",
    "**Nota**: En esta sección implementaremos:\n",
    "* Cálculo de métricas\n",
    "* Comparación de resultados\n",
    "* Validación de comunidades\n",
    "* Visualización de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación de comunidades: modularidad, conductancia y métricas externas si hay ground truth\n",
    "from collections import defaultdict\n",
    "\n",
    "def conductance(G, community_nodes):\n",
    "    cut = 0\n",
    "    volS = 0\n",
    "    for u in community_nodes:\n",
    "        volS += G.degree(u)\n",
    "        for v in G.neighbors(u):\n",
    "            if v not in community_nodes:\n",
    "                cut += 1\n",
    "    vol_rest = sum(dict(G.degree()).values()) - volS\n",
    "    denom = min(volS, vol_rest) if min(volS, vol_rest) > 0 else 1\n",
    "    return cut / denom\n",
    "\n",
    "if 'partition' in globals() and partition:\n",
    "    try:\n",
    "        import community as community_louvain\n",
    "        mod = community_louvain.modularity(partition, G)\n",
    "        print('Modularidad (Louvain):', round(mod, 4))\n",
    "    except Exception as e:\n",
    "        print('No se pudo calcular modularidad (python-louvain):', e)\n",
    "\n",
    "    # Conductance for top communities\n",
    "    comms = defaultdict(list)\n",
    "    for n, c in partition.items():\n",
    "        comms[c].append(n)\n",
    "    top = sorted(comms.items(), key=lambda x: len(x[1]), reverse=True)[:3]\n",
    "    for cid, nodes in top:\n",
    "        print(f'Conductancia comunidad {cid} (tam={len(nodes)}):', round(conductance(G, set(nodes)), 4))\n",
    "\n",
    "else:\n",
    "    print('No hay partición disponible para evaluación. Ejecuta la celda de detección de comunidades.')\n",
    "\n",
    "# Evaluación externa si hay ground truth en dict `true_labels` (node -> label)\n",
    "try:\n",
    "    from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "    if 'true_labels' in globals() and 'partition' in globals() and partition:\n",
    "        nodes_common = [n for n in G.nodes() if n in true_labels and n in partition]\n",
    "        y_true = [true_labels[n] for n in nodes_common]\n",
    "        y_pred = [partition[n] for n in nodes_common]\n",
    "        print('NMI:', round(normalized_mutual_info_score(y_true, y_pred), 4))\n",
    "        print('ARI:', round(adjusted_rand_score(y_true, y_pred), 4))\n",
    "except Exception as e:\n",
    "    # sklearn puede no estar instalado o no haber ground truth\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6836a",
   "metadata": {},
   "source": [
    "## 6.1 Dinámica de Comunidades\n",
    "* Nacimiento y muerte\n",
    "* Fusión y división\n",
    "* Crecimiento y contracción\n",
    "* Estabilidad y cambio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0573056",
   "metadata": {},
   "source": [
    "## 6.2 Métricas Temporales\n",
    "* Supervivencia de comunidades\n",
    "* Tasa de cambio\n",
    "* Persistencia de membresía\n",
    "* Evolución estructural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d79994",
   "metadata": {},
   "source": [
    "## 6.3 Patrones de Evolución\n",
    "* Ciclos de vida\n",
    "* Puntos de transición\n",
    "* Factores de cambio\n",
    "* Predicción de evolución\n",
    "\n",
    "**Nota**: En esta sección implementaremos:\n",
    "* Análisis de series temporales\n",
    "* Tracking de comunidades\n",
    "* Visualización de evolución\n",
    "* Predicción de cambios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a8840",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusión\n",
    "Este notebook servirá como guía para el análisis de comunidades en redes, con implementaciones prácticas, ejemplos y visualizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9996153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo simple de slicing temporal (si hay timestamps en columna 3)\n",
    "from collections import defaultdict\n",
    "\n",
    "def slice_windows(path, window_size=86400, max_lines=None):\n",
    "    windows = defaultdict(list)\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if max_lines and i>=max_lines: break\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 3:\n",
    "                if len(parts) >= 2:\n",
    "                    windows[0].append((parts[0], parts[1]))\n",
    "                continue\n",
    "            try:\n",
    "                t = int(parts[2])\n",
    "            except:\n",
    "                continue\n",
    "            win = (t//window_size)*window_size\n",
    "            windows[win].append((parts[0], parts[1]))\n",
    "    return windows\n",
    "\n",
    "print('Si tu edgelist incluye timestamps, usa slice_windows para crear snapshots por ventana.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
